{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('train_data.json', 'r') as f:\n",
    "    data = f.read()\n",
    "    data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_id': 92575, 'review': '종합 평점은 4점 드립니다.', 'rating': 4, 'date': '15.08.26'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = [dic['review'] for dic in data]\n",
    "rating = [dic['rating'] for dic in data]\n",
    "\n",
    "sep = int(len(review)*0.9)\n",
    "\n",
    "train_review = review[:sep]\n",
    "train_rating = rating[:sep]\n",
    "val_review = review[sep:]\n",
    "val_rating = rating[sep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Twitter\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from random import shuffle\n",
    "\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize(doc):\n",
    "        return ['/'.join(t) for t in pos_tagger.pos(str(doc), norm=True, stem=True)]\n",
    "\n",
    "def make_wv(data,tag=True,using_tag = ['Noun','Verb','Adjective'],size=100,window=5,min_count=50,workers=4):\n",
    "        \n",
    "    if tag is True:\n",
    "        try:\n",
    "            data_tag = [tokenize(x) for x in data]\n",
    "        except:\n",
    "            print(data)\n",
    "            raise\n",
    "    else:\n",
    "        data_tag = x\n",
    "    \n",
    "    def tag_filter(x):\n",
    "        out = []\n",
    "        for t in x:\n",
    "            if t.split('/')[1] in using_tag:\n",
    "                out.append(t)\n",
    "        return out\n",
    "    \n",
    "    data_filter = [tag_filter(x) for x in data_tag]\n",
    "    model = Word2Vec(data_filter, size=size, window=window, min_count=min_count, iter=10, workers=workers)\n",
    "    return model\n",
    "    \n",
    "    #wv_df =pd.DataFrame(model.wv[model.wv.vocab])\n",
    "    \n",
    "    #return pd.concat([pd.Series(list(model.wv.vocab.keys())),wv_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv = make_wv(train_review) # train, val 나눠서 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('여자/Noun', 0.8290437459945679)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from konlpy.utils import pprint\n",
    "pprint(wv.most_similar(positive=tokenize(u'여배우 남자'), negative=tokenize(u'배우'), topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voca = list(wv.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed = wv.wv[wv.wv.vocab]\n",
    "voca = list(wv.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sen2vec(sentence):\n",
    "    token = tokenize(sentence)\n",
    "    vec = [0 for i in range(100)]\n",
    "    count = 0\n",
    "    for word in token:\n",
    "        if word in voca:\n",
    "            vec = [i+j for i, j in zip(vec, embed[voca.index(word)])]\n",
    "    if count == 0:\n",
    "        return vec\n",
    "    else:\n",
    "        return [i/count for i in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_review_vec = [sen2vec(i) for i in train_review]\n",
    "val_review_vec = [sen2vec(i) for i in val_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(x):\n",
    "    if x >= 1 and x <=3:\n",
    "        return 'NEG'\n",
    "    elif x >= 4 and x <= 7:\n",
    "        return 'NEU'\n",
    "    else:\n",
    "        return 'POS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6314"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor()\n",
    "regr.fit(train_review_vec, train_rating)\n",
    "\n",
    "val_label = list(map(labeling, val_rating))\n",
    "val_pred_label = list(map(labeling, regr.predict(val_review_vec)))\n",
    "\n",
    "sum([i==j for i, j in zip(val_label, val_pred_label)])/len(val_pred_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
